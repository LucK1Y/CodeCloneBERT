{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Explanation\n",
    "This jupyter notebook contains all the code to finetune the roberta model on the semantic-benchmark dataset. It should always be kept uptodate.\n",
    "\n",
    "**Note**: Maybe you need to adjust the paths to the dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import RobertaTokenizerFast, RobertaTokenizerFast, RobertaForSequenceClassification, RobertaConfig, Trainer, TrainingArguments\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import Dataset, load_dataset\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import accelerate\n",
    "from transformers import EarlyStoppingCallback, IntervalStrategy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T08:55:43.700984Z",
     "start_time": "2024-04-09T08:55:43.697486Z"
    }
   },
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Constants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MODEL_NAME = \"microsoft/codebert-base\"\n",
    "USE_CPU = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T08:49:16.102119Z",
     "start_time": "2024-04-09T08:49:16.098515Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Load Dataset:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['Unnamed: 0', 'clone1', 'clone2', 'semantic_clone'],\n    num_rows: 2000\n})"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"..\") # navigate to base-directory\n",
    "dataset_path = Path(\"data/semantic_benchmark_dataset.csv\")\n",
    "if not dataset_path.exists():\n",
    "    raise Exception(f\"Could not find the the dataset in path: {dataset_path.absolute()}\")\n",
    "\n",
    "dataset = load_dataset('csv', data_files=str(dataset_path), split=\"train\") # in kaggle we need to load it into a pandas, then load it into a dataset\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T08:49:18.054478Z",
     "start_time": "2024-04-09T08:49:17.384393Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Tokenize the complete Dataset before Fine-Tuning\n",
    "Note: they are stored on the CPU at the moment, but the trainer will move them to the GPU automatically during fine-tuning."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def tokenization(row):\n",
    "    tokenized_inputs = tokenizer([row[\"clone1\"], row[\"clone2\"]], padding=\"max_length\", truncation=True, return_tensors=\"pt\",\n",
    "                                 max_length=257)\n",
    "    tokenized_inputs[\"input_ids\"] = tokenized_inputs[\"input_ids\"].flatten()\n",
    "    tokenized_inputs[\"attention_mask\"] = tokenized_inputs[\"attention_mask\"].flatten()\n",
    "    return tokenized_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T08:49:19.998595Z",
     "start_time": "2024-04-09T08:49:19.994791Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "\n",
    "dataset = dataset.rename_column(\"semantic_clone\", \"label\") # the Huggingface library expects the column name label\n",
    "dataset = dataset.map(tokenization, batched=False) # using batched would not allow the current nifty trick\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]) # make sure everything are tensors"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T08:49:22.255599Z",
     "start_time": "2024-04-09T08:49:21.911343Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create the dataset splits: (Train: 60, Evaluation:10, Testing: 30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0239e9674cb44464a5660a80751dd454"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "3822211"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.shuffle(seed=42) # randomize dataset: currently first 1000: clones, last 1000 not clones\n",
    "dataset_train = dataset.select(range(1200)) # select the first 1200 for training and evaluation (during training)\n",
    "dataset_train = dataset_train.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "proper_test_dataset = dataset.select(range(1200,2000))\n",
    "proper_test_dataset.to_csv(\"proper_test_dataset.csv\") # save them to be able to repeat scores on model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T08:49:29.584967Z",
     "start_time": "2024-04-09T08:49:28.832971Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if USE_CPU:\n",
    "    device = torch.device(\"cpu\")\n",
    "else: # Cuda=GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T08:49:37.544807Z",
     "start_time": "2024-04-09T08:49:37.540772Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(MODEL_NAME, num_labels=2) # Binary Classification Task: 2 labels\n",
    "model = RobertaForSequenceClassification.from_pretrained(MODEL_NAME, config=config).to(device)\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "f1 = evaluate.load(\"f1\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T08:49:48.073261Z",
     "start_time": "2024-04-09T08:49:43.310442Z"
    }
   },
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"], \"precision\": precision.compute(predictions=predictions, references=labels)[\"precision\"], \"recall\": recall.compute(predictions=predictions, references=labels)[\"recall\"], \"f1\": f1.compute(predictions=predictions, references=labels)[\"f1\"]}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T08:49:48.077197Z",
     "start_time": "2024-04-09T08:49:48.074258Z"
    }
   },
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Sanity check to see if everything is setup correctly:\n",
    "Hint: the scores calculate might print some warnings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luc/repos/zest/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/luc/repos/zest/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/luc/repos/zest/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'accuracy': 1.0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_input_ids = dataset_train[\"train\"][\"input_ids\"][1:2].to(device)\n",
    "batch_attention_mask = dataset_train[\"train\"][\"attention_mask\"][1:2].to(device)\n",
    "batch_labels = dataset_train[\"train\"][\"label\"][1:2].to(device)\n",
    "output = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n",
    "\n",
    "compute_metrics((output.logits.detach().numpy(), batch_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T08:54:18.153204Z",
     "start_time": "2024-04-09T08:54:17.593216Z"
    }
   },
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Training Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luc/repos/zest/.venv/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=2e-5,             # Learning rate\n",
    "    adam_epsilon=1e-8,              # Epsilon for Adam optimizer\n",
    "    num_train_epochs=30,             # Total number of training epochs\n",
    "    logging_dir='./logs',           # Directory for storing logs\n",
    "    logging_steps=BATCH_SIZE,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=BATCH_SIZE,\n",
    "    output_dir =\"./output\",\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4, # how many cpus to use to load the data while training\n",
    "    do_eval=True,                 # Perform evaluation at the end of training\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=BATCH_SIZE,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = 'f1',\n",
    "    save_total_limit=2,\n",
    "    use_cpu=USE_CPU\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train[\"train\"],\n",
    "    eval_dataset=dataset_train[\"test\"],      # Evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T08:58:49.970150Z",
     "start_time": "2024-04-09T08:58:49.946420Z"
    }
   },
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Start Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-09T08:59:11.801577Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# continue training from a checkpoint:\n",
    "# trainer.train(resume_from_checkpoint=True)\n",
    "\n",
    "# calculate the scores of the returning/best model on the evaluation dataset\n",
    "# trainer.evaluate()\n",
    "\n",
    "# store model to disk (same as best checkpoint)\n",
    "# trainer.save_model(f\"semantic_fine_tuned2\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate on the Test Dataset\n",
    "trainer.evaluate(proper_test_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### (Cleaning Memory)\n",
    "rerun below cells a few time (especially if you stopped with an error above)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "66"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "del model\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T12:54:05.243610Z",
     "start_time": "2024-03-28T12:54:05.114878Z"
    }
   },
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "1/0"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

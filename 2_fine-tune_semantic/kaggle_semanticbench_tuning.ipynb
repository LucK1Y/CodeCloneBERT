{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 7973182,
     "sourceType": "datasetVersion",
     "datasetId": 4691804
    }
   ],
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# import os\n",
    "\n",
    "# os.chdir(\"..\")\n",
    "!ls\n",
    "# !pwd\n",
    "# !rm -rf input"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T12:42:59.157151Z",
     "start_time": "2024-03-28T12:42:59.149967Z"
    },
    "execution": {
     "iopub.status.busy": "2024-04-09T10:03:08.287648Z",
     "iopub.execute_input": "2024-04-09T10:03:08.288367Z",
     "iopub.status.idle": "2024-04-09T10:03:09.281322Z",
     "shell.execute_reply.started": "2024-04-09T10:03:08.288334Z",
     "shell.execute_reply": "2024-04-09T10:03:09.280234Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": "logs  output  proper_test_dataset.csv  semantic_fine_tuned2\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy; print(numpy.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T12:56:41.446900Z",
     "start_time": "2024-03-28T12:56:41.442555Z"
    },
    "execution": {
     "iopub.status.busy": "2024-04-09T10:03:10.015071Z",
     "iopub.execute_input": "2024-04-09T10:03:10.015916Z",
     "iopub.status.idle": "2024-04-09T10:03:10.021377Z",
     "shell.execute_reply.started": "2024-04-09T10:03:10.015883Z",
     "shell.execute_reply": "2024-04-09T10:03:10.020281Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": "1.26.4\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# %pip install datasets==2.18.0\n",
    "# !pip install --upgrade pandas\n",
    "# %pip install evaluate\n",
    "# !pip install pandas==1.4.3\n",
    "!pip install evaluate\n",
    "# !pip install numpy==1.19.5\n",
    "# !pip install accelerate\n",
    "# !pip install --upgrade torch"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-09T10:03:11.061441Z",
     "iopub.execute_input": "2024-04-09T10:03:11.061817Z",
     "iopub.status.idle": "2024-04-09T10:03:25.737181Z",
     "shell.execute_reply.started": "2024-04-09T10:03:11.061788Z",
     "shell.execute_reply": "2024-04-09T10:03:25.735961Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": "Collecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nCollecting responses<0.19 (from evaluate)\n  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m84.1/84.1 kB\u001B[0m \u001B[31m4.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\nInstalling collected packages: responses, evaluate\nSuccessfully installed evaluate-0.4.1 responses-0.18.0\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas; print(pandas.__version__)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-09T10:03:26.684073Z",
     "iopub.execute_input": "2024-04-09T10:03:26.684649Z",
     "iopub.status.idle": "2024-04-09T10:03:26.690268Z",
     "shell.execute_reply.started": "2024-04-09T10:03:26.684612Z",
     "shell.execute_reply": "2024-04-09T10:03:26.689315Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": "2.2.1\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import RobertaConfig, RobertaTokenizerFast,RobertaForSequenceClassification, Trainer, TrainingArguments, RobertaTokenizer\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import Dataset, load_dataset\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import accelerate\n",
    "import pandas as pd\n",
    "\n",
    "dataset_path = Path(\"/kaggle/input/semanticbenchmark-dataset/semantic_benchmark_dataset_2.csv\")\n",
    "print(dataset_path.exists())\n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Convert the Pandas DataFrame into a datasets Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "\n",
    "# dataset = load_dataset('csv', data_files=str(dataset_path), split=\"train\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T12:56:40.962156Z",
     "start_time": "2024-03-28T12:56:40.272259Z"
    },
    "execution": {
     "iopub.status.busy": "2024-04-09T10:03:29.588667Z",
     "iopub.execute_input": "2024-04-09T10:03:29.589504Z",
     "iopub.status.idle": "2024-04-09T10:03:48.678387Z",
     "shell.execute_reply.started": "2024-04-09T10:03:29.589472Z",
     "shell.execute_reply": "2024-04-09T10:03:48.677400Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "text": "2024-04-09 10:03:39.510724: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-09 10:03:39.510856: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-09 10:03:39.646718: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "True\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df[\"semantic_clone\"].value_counts()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-09T10:03:48.680283Z",
     "iopub.execute_input": "2024-04-09T10:03:48.680562Z",
     "iopub.status.idle": "2024-04-09T10:03:48.694057Z",
     "shell.execute_reply.started": "2024-04-09T10:03:48.680538Z",
     "shell.execute_reply": "2024-04-09T10:03:48.692912Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [
    {
     "execution_count": 8,
     "output_type": "execute_result",
     "data": {
      "text/plain": "semantic_clone\n1    1000\n0    1000\nName: count, dtype: int64"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model_name = \"microsoft/codebert-base\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_name)\n",
    "# tokenizer = RobertaTokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T12:56:42.601104Z",
     "start_time": "2024-03-28T12:56:42.115459Z"
    },
    "execution": {
     "iopub.status.busy": "2024-04-09T10:03:48.695407Z",
     "iopub.execute_input": "2024-04-09T10:03:48.695800Z",
     "iopub.status.idle": "2024-04-09T10:03:51.238735Z",
     "shell.execute_reply.started": "2024-04-09T10:03:48.695765Z",
     "shell.execute_reply": "2024-04-09T10:03:51.237873Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3563ee866b84e7faf279eb0fe061652"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08134da98f4747c4860eafcb6a760b4a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b16d5f1d2e8b466db81be855952f901e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe64499c3f194a28aa4927e0f957f70d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d5c7b14bd5b34030b38500304798fc6e"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset.rename_column(\"semantic_clone\", \"label\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T12:56:43.391098Z",
     "start_time": "2024-03-28T12:56:43.385422Z"
    },
    "execution": {
     "iopub.status.busy": "2024-04-09T10:03:53.554945Z",
     "iopub.execute_input": "2024-04-09T10:03:53.555350Z",
     "iopub.status.idle": "2024-04-09T10:03:53.562557Z",
     "shell.execute_reply.started": "2024-04-09T10:03:53.555319Z",
     "shell.execute_reply": "2024-04-09T10:03:53.561314Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "514/2"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-08T07:35:21.429377Z",
     "iopub.execute_input": "2024-04-08T07:35:21.429867Z",
     "iopub.status.idle": "2024-04-08T07:35:21.440112Z",
     "shell.execute_reply.started": "2024-04-08T07:35:21.429828Z",
     "shell.execute_reply": "2024-04-08T07:35:21.438609Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "511 / 2"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-08T07:35:22.123842Z",
     "iopub.execute_input": "2024-04-08T07:35:22.124320Z",
     "iopub.status.idle": "2024-04-08T07:35:22.133892Z",
     "shell.execute_reply.started": "2024-04-08T07:35:22.124281Z",
     "shell.execute_reply": "2024-04-08T07:35:22.132134Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def tokenization(row): \n",
    "    tokenized_inputs = tokenizer([row[\"clone1\"], row[\"clone2\"]], padding=\"max_length\", truncation=True, return_tensors=\"pt\",\n",
    "                                 max_length=255)\n",
    "    tokenized_inputs[\"input_ids\"] = tokenized_inputs[\"input_ids\"].flatten()\n",
    "    tokenized_inputs[\"attention_mask\"] = tokenized_inputs[\"attention_mask\"].flatten()\n",
    "#     print(tokenized_inputs.shape)\n",
    "    return tokenized_inputs\n",
    "\n",
    "dataset = dataset.map(tokenization, batched=False)\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T12:56:44.766584Z",
     "start_time": "2024-03-28T12:56:44.171503Z"
    },
    "execution": {
     "iopub.status.busy": "2024-04-09T10:03:57.108758Z",
     "iopub.execute_input": "2024-04-09T10:03:57.109681Z",
     "iopub.status.idle": "2024-04-09T10:04:00.191449Z",
     "shell.execute_reply.started": "2024-04-09T10:03:57.109644Z",
     "shell.execute_reply": "2024-04-09T10:04:00.190375Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3dc0b15df239429b822a28ddfb7da177"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-08T11:46:48.422616Z",
     "iopub.execute_input": "2024-04-08T11:46:48.422988Z",
     "iopub.status.idle": "2024-04-08T11:46:48.429472Z",
     "shell.execute_reply.started": "2024-04-08T11:46:48.422958Z",
     "shell.execute_reply": "2024-04-08T11:46:48.428627Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset.shuffle(seed=42)\n",
    "dataset_train = dataset.select(range(1200))\n",
    "proper_test_dataset = dataset.select(range(1200,2000))\n",
    "proper_test_dataset.to_csv(\"proper_test_dataset.csv\")\n",
    "\n",
    "dataset_train = dataset_train.train_test_split(test_size=0.16, seed=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T12:56:46.256199Z",
     "start_time": "2024-03-28T12:56:46.236917Z"
    },
    "execution": {
     "iopub.status.busy": "2024-04-09T10:04:04.080738Z",
     "iopub.execute_input": "2024-04-09T10:04:04.081460Z",
     "iopub.status.idle": "2024-04-09T10:04:06.902214Z",
     "shell.execute_reply.started": "2024-04-09T10:04:04.081423Z",
     "shell.execute_reply": "2024-04-09T10:04:06.901421Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dae5e6c9b3cb46949d6c57df3720ea56"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_train"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-08T11:47:41.753721Z",
     "iopub.execute_input": "2024-04-08T11:47:41.754407Z",
     "iopub.status.idle": "2024-04-08T11:47:41.759968Z",
     "shell.execute_reply.started": "2024-04-08T11:47:41.754377Z",
     "shell.execute_reply": "2024-04-08T11:47:41.759062Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "np.object = np.object_\n",
    "dataset_train[\"train\"][\"input_ids\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T12:56:48.173580Z",
     "start_time": "2024-03-28T12:56:48.167994Z"
    },
    "execution": {
     "iopub.status.busy": "2024-04-09T10:04:12.861895Z",
     "iopub.execute_input": "2024-04-09T10:04:12.862582Z",
     "iopub.status.idle": "2024-04-09T10:04:12.920747Z",
     "shell.execute_reply.started": "2024-04-09T10:04:12.862549Z",
     "shell.execute_reply": "2024-04-09T10:04:12.919716Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": [
    {
     "execution_count": 13,
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[    0,  9232,  5448,  ..., 50117, 50117,     2],\n        [    0,  9232,  5448,  ...,     1,     1,     1],\n        [    0,  9232,  5448,  ..., 50118, 50117,     2],\n        ...,\n        [    0,  9232,  5448,  ...,     1,     1,     1],\n        [    0,  9232,  5448,  ...,     1,     1,     1],\n        [    0,  9232,  5448,  ...,  4832, 50118,     2]])"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "config = RobertaConfig.from_pretrained(model_name, num_labels=2)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name, config=config).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T12:56:50.474236Z",
     "start_time": "2024-03-28T12:56:49.924232Z"
    },
    "execution": {
     "iopub.status.busy": "2024-04-09T10:04:18.449998Z",
     "iopub.execute_input": "2024-04-09T10:04:18.450687Z",
     "iopub.status.idle": "2024-04-09T10:04:21.910361Z",
     "shell.execute_reply.started": "2024-04-09T10:04:18.450655Z",
     "shell.execute_reply": "2024-04-09T10:04:21.909411Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a51181c4eea947e0a9a1b4f0bb84d31f"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-09T10:04:22.084951Z",
     "iopub.execute_input": "2024-04-09T10:04:22.085365Z",
     "iopub.status.idle": "2024-04-09T10:04:22.090178Z",
     "shell.execute_reply.started": "2024-04-09T10:04:22.085332Z",
     "shell.execute_reply": "2024-04-09T10:04:22.089114Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "config.max_position_embeddings"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-08T07:35:40.476955Z",
     "iopub.execute_input": "2024-04-08T07:35:40.477423Z",
     "iopub.status.idle": "2024-04-08T07:35:40.485927Z",
     "shell.execute_reply.started": "2024-04-08T07:35:40.477387Z",
     "shell.execute_reply": "2024-04-08T07:35:40.484502Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# dataset_train[\"train\"][0][\"attention_mask\"].shape\n",
    "for sample in dataset:\n",
    "    if sample[\"attention_mask\"].shape != torch.Size([514]) or sample[\"input_ids\"].shape != torch.Size([514]):\n",
    "      print(f\"Unexpected shape found: {sample}\")\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-08T07:08:23.802164Z",
     "iopub.execute_input": "2024-04-08T07:08:23.802616Z",
     "iopub.status.idle": "2024-04-08T07:08:24.667154Z",
     "shell.execute_reply.started": "2024-04-08T07:08:23.802582Z",
     "shell.execute_reply": "2024-04-08T07:08:24.665842Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.roberta.embeddings.word_embeddings"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-08T07:08:25.954016Z",
     "iopub.execute_input": "2024-04-08T07:08:25.955353Z",
     "iopub.status.idle": "2024-04-08T07:08:25.963602Z",
     "shell.execute_reply.started": "2024-04-08T07:08:25.955286Z",
     "shell.execute_reply": "2024-04-08T07:08:25.962363Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "unique_ids = set()\n",
    "for sample in dataset:\n",
    "  unique_ids.update(set(sample[\"input_ids\"].tolist()))  # Convert input_ids to a list and add unique IDs to the set\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-08T07:08:27.314814Z",
     "iopub.execute_input": "2024-04-08T07:08:27.315276Z",
     "iopub.status.idle": "2024-04-08T07:08:28.302557Z",
     "shell.execute_reply.started": "2024-04-08T07:08:27.315241Z",
     "shell.execute_reply": "2024-04-08T07:08:28.301286Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "word_embeddings = model.roberta.embeddings.word_embeddings\n",
    "for unique_id in unique_ids:\n",
    "  x = word_embeddings(torch.tensor([unique_id]))\n",
    "  if x == None :\n",
    "        print(unique_id)\n",
    "\n",
    "max(unique_ids)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-08T07:08:30.712459Z",
     "iopub.execute_input": "2024-04-08T07:08:30.712853Z",
     "iopub.status.idle": "2024-04-08T07:08:31.022966Z",
     "shell.execute_reply.started": "2024-04-08T07:08:30.712824Z",
     "shell.execute_reply": "2024-04-08T07:08:31.021748Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for unique_id in unique_ids:\n",
    "    print(tokenizer.create_position_ids_from_input_ids(unique_id))\n",
    "    break"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "config"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-08T07:08:33.951016Z",
     "iopub.execute_input": "2024-04-08T07:08:33.951579Z",
     "iopub.status.idle": "2024-04-08T07:08:33.961044Z",
     "shell.execute_reply.started": "2024-04-08T07:08:33.951539Z",
     "shell.execute_reply": "2024-04-08T07:08:33.959687Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "batch_input_ids = dataset_train[\"train\"][\"input_ids\"][0:2]\n",
    "batch_attention_mask = dataset_train[\"train\"][\"attention_mask\"][0:2]\n",
    "\n",
    "model(input_ids=batch_input_ids.to(device), attention_mask=batch_attention_mask.to(device))\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-08T07:36:26.219014Z",
     "iopub.execute_input": "2024-04-08T07:36:26.219546Z",
     "iopub.status.idle": "2024-04-08T07:36:28.200820Z",
     "shell.execute_reply.started": "2024-04-08T07:36:26.219509Z",
     "shell.execute_reply": "2024-04-08T07:36:28.199538Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "from transformers import EarlyStoppingCallback, IntervalStrategy\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "# train_dataloader = DataLoader(dataset_train[\"train\"], batch_size=2, shuffle=True)\n",
    "# eval_dataloader = DataLoader(dataset_train[\"test\"], batch_size=2)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"], \"precision\": precision.compute(predictions=predictions, references=labels)[\"precision\"], \"recall\": recall.compute(predictions=predictions, references=labels)[\"recall\"], \"f1\": f1.compute(predictions=predictions, references=labels)[\"f1\"]}\n",
    "\n",
    "# optimizer: AdamW default\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=16,  # Batch size per GPU/TPU core/CPU for training\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,             # Learning rate\n",
    "    adam_epsilon=1e-8,              # Epsilon for Adam optimizer\n",
    "    num_train_epochs=30,             # Total number of training epochs\n",
    "    # block_size=400,                 # Block size\n",
    "    logging_dir='./logs',           # Directory for storing logs\n",
    "    logging_steps=16,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=16,\n",
    "    output_dir =\"./output\",\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    report_to=None,\n",
    "    do_eval=True,                 # Perform evaluation at the end of training\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=16,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = 'f1',\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "# Define the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train[\"train\"],\n",
    "    eval_dataset=dataset_train[\"test\"],      # Evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=4)],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "# trainer.train(resume_from_checkpoint=True)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T13:03:33.645360Z",
     "start_time": "2024-03-28T13:03:31.191503Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# trainer.train(resume_from_checkpoint=True)\n",
    "# trainer.evaluate()\n",
    "# trainer.save_model(f\"semantic_fine_tuned2\")\n",
    "trainer.evaluate(proper_test_dataset)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-09T10:19:10.308113Z",
     "iopub.execute_input": "2024-04-09T10:19:10.308525Z",
     "iopub.status.idle": "2024-04-09T10:19:25.063892Z",
     "shell.execute_reply.started": "2024-04-09T10:19:10.308492Z",
     "shell.execute_reply": "2024-04-09T10:19:25.062640Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [25/25 00:13]\n    </div>\n    "
     },
     "metadata": {}
    },
    {
     "execution_count": 19,
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'eval_loss': 0.30004990100860596,\n 'eval_accuracy': 0.9125,\n 'eval_precision': 0.8883610451306413,\n 'eval_recall': 0.9420654911838791,\n 'eval_f1': 0.9144254278728605,\n 'eval_runtime': 14.7417,\n 'eval_samples_per_second': 54.268,\n 'eval_steps_per_second': 1.696,\n 'epoch': 8.5}"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "import gc\n",
    "\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T12:54:05.243610Z",
     "start_time": "2024-03-28T12:54:05.114878Z"
    },
    "execution": {
     "iopub.status.busy": "2024-04-08T06:39:41.134367Z",
     "iopub.status.idle": "2024-04-08T06:39:41.134922Z",
     "shell.execute_reply.started": "2024-04-08T06:39:41.134658Z",
     "shell.execute_reply": "2024-04-08T06:39:41.134680Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# del model\n",
    "# del trainer\n",
    "# torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T12:54:02.907293Z",
     "start_time": "2024-03-28T12:54:02.893305Z"
    },
    "execution": {
     "iopub.status.busy": "2024-04-08T06:39:41.136466Z",
     "iopub.status.idle": "2024-04-08T06:39:41.136951Z",
     "shell.execute_reply.started": "2024-04-08T06:39:41.136718Z",
     "shell.execute_reply": "2024-04-08T06:39:41.136737Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!zip -r /kaggle/working/best-model.zip /kaggle/working/semantic_fine_tuned2/*\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-09T10:22:54.344648Z",
     "iopub.execute_input": "2024-04-09T10:22:54.345567Z",
     "iopub.status.idle": "2024-04-09T10:23:23.063455Z",
     "shell.execute_reply.started": "2024-04-09T10:22:54.345521Z",
     "shell.execute_reply": "2024-04-09T10:23:23.062252Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "  adding: kaggle/working/semantic_fine_tuned2/config.json (deflated 50%)\n  adding: kaggle/working/semantic_fine_tuned2/model.safetensors (deflated 7%)\n  adding: kaggle/working/semantic_fine_tuned2/training_args.bin (deflated 51%)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
